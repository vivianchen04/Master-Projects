{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ec7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1e33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will suppress any warnings, comment out if you'd like to preserve them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dee5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check formatting of submissions\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017e859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4adf02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"spoilers.json.gz\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4185ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9dfe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6e6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few utility data structures\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['user_id'],d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    reviewsPerItem[i].append(d)\n",
    "\n",
    "# Sort reviews per user by timestamp\n",
    "for u in reviewsPerUser:\n",
    "    reviewsPerUser[u].sort(key=lambda x: x['timestamp'])\n",
    "    \n",
    "# Same for reviews per item\n",
    "for i in reviewsPerItem:\n",
    "    reviewsPerItem[i].sort(key=lambda x: x['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a9a4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2012-03-13',\n",
       " '2013-05-06',\n",
       " '2013-09-03',\n",
       " '2015-04-05',\n",
       " '2016-02-10',\n",
       " '2016-05-29']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E.g. reviews for this user are sorted from earliest to most recent\n",
    "[d['timestamp'] for d in reviewsPerUser['b0d7e561ca59e313b728dc30a5b1862e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f37c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d514c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypred):\n",
    "    return sum([(a-b)**2 for (a,b) in zip(y,ypred)]) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94953745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "y = []\n",
    "y_pred = []\n",
    "for u in reviewsPerUser:\n",
    "    cur = []\n",
    "    reviews = reviewsPerUser[u]\n",
    "    for i in range(0, len(reviews) - 1):\n",
    "        cur.append(reviews[i]['rating'])\n",
    "    if len(cur) == 0:\n",
    "        continue\n",
    "    y_pred.append(sum(cur)/len(cur))\n",
    "    y.append(reviews[-1]['rating'])\n",
    "answers['Q1a'] = MSE(y, y_pred)\n",
    "assertFloat(answers['Q1a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ae83772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "y = []\n",
    "y_pred = []\n",
    "for u in reviewsPerItem:\n",
    "    cur = []\n",
    "    reviews = reviewsPerItem[u]\n",
    "    for i in range(0, len(reviews) - 1):\n",
    "        cur.append(reviews[i]['rating'])\n",
    "    if len(cur) == 0:\n",
    "        continue\n",
    "    y_pred.append(sum(cur)/len(cur))\n",
    "    y.append(reviews[-1]['rating'])\n",
    "answers['Q1b'] = MSE(y, y_pred)\n",
    "assertFloat(answers['Q1b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009dbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2\n",
    "answers['Q2'] = []\n",
    "\n",
    "for N in [1,2,3]:\n",
    "    y = []\n",
    "    y_pred = []\n",
    "    for u in reviewsPerUser:\n",
    "        cur = []\n",
    "        reviews = reviewsPerUser[u]\n",
    "        for i in range(0, len(reviews) - 1):\n",
    "            cur.append(reviews[i]['rating'])\n",
    "        if len(cur) == 0:\n",
    "            continue\n",
    "        \n",
    "        if len(cur) < N:\n",
    "            cur_new = cur\n",
    "        \n",
    "        if len(cur) >= N:\n",
    "            cur_new = cur[-N:]\n",
    "        \n",
    "        y_pred.append(sum(cur_new)/len(cur_new))\n",
    "        y.append(reviews[-1]['rating'])\n",
    "            \n",
    "    answers['Q2'].append(MSE(y,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58058dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4cf1e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8923b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48b49b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature3(N, u): # For a user u and a window size of N\n",
    "    \n",
    "    cur = []\n",
    "    reviews = reviewsPerUser[u]\n",
    "    for i in range(0, len(reviews) - 1):\n",
    "        cur.append(reviews[i]['rating'])\n",
    "    \n",
    "    feat = [1]\n",
    "    for n in range(1, N + 1):\n",
    "        feat.append(cur[-n])\n",
    "\n",
    "    return feat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05d3b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3a'] = [feature3(2,dataset[0]['user_id']), feature3(3,dataset[0]['user_id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "affcb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q3a']) == 2\n",
    "assert len(answers['Q3a'][0]) == 3\n",
    "assert len(answers['Q3a'][1]) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64fddaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237],\n",
       " 'Q3a': [[1, 4, 4], [1, 4, 4, 4]],\n",
       " 'Q3b': [1.5608319121482275, 1.5409512373315701, 1.5396484853948436]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 3b\n",
    "answers['Q3b'] = []\n",
    "def feat(N, u):\n",
    "    feat = [1]\n",
    "    data = reviewsPerUser[u]\n",
    "    for d in data[-N-1:-1]:\n",
    "        feat.append(d['rating'])\n",
    "    return feat\n",
    "\n",
    "for N in [1,2,3]:\n",
    "    X = []\n",
    "    y = []\n",
    "    for u,data in reviewsPerUser.items():\n",
    "        if len(data) <= N:\n",
    "            continue\n",
    "        else:\n",
    "            X.append(feat(N,u))\n",
    "            y.append(data[-1]['rating'])\n",
    "    model = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    mse = MSE(y, y_pred)\n",
    "    answers['Q3b'].append(mse)\n",
    "assertFloatList(answers['Q3b'], 3)\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc7c338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237],\n",
       " 'Q3a': [[1, 4, 4], [1, 4, 4, 4]],\n",
       " 'Q3b': [1.5608319121482275, 1.5409512373315701, 1.5396484853948436],\n",
       " 'Q4a': [[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       "  [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 4a\n",
    "globalAverage = [d['rating'] for d in dataset]\n",
    "globalAverage = sum(globalAverage) / len(globalAverage)\n",
    "\n",
    "def featureMeanValue(N, u): # For a user u and a window size of N\n",
    "    feat = [1]\n",
    "    data = reviewsPerUser[u]\n",
    "    if len(data) < N + 1:\n",
    "        if len(data) < 2:\n",
    "            for j in range(N):\n",
    "                feat.append(globalAverage)\n",
    "        elif len(data) >= 2:\n",
    "            rate = [review['rating'] for review in data[:-1]]\n",
    "            avg = sum(rate)/len(rate)\n",
    "            for i in range(len(data)-1):\n",
    "                feat.append(data[-i-2]['rating'])\n",
    "            for i in range(N-len(data)+1):\n",
    "                feat.append(avg)\n",
    "    else:\n",
    "        for i in range(N):\n",
    "            feat.append(data[-i-2]['rating'])  \n",
    "    return feat\n",
    "\n",
    "def featureMissingValue(N, u):\n",
    "    feat = [1]\n",
    "    data = reviewsPerUser[u]\n",
    "\n",
    "    if len(data) < N + 1:\n",
    "        if len(data) < 2:\n",
    "            for j in range(N):\n",
    "                feat.append(1)\n",
    "                feat.append(0)\n",
    "        elif len(data) >= 2:\n",
    "            for i in range(len(data)-1):\n",
    "                feat.append(0)\n",
    "                feat.append(data[- i - 2]['rating'])\n",
    "            for i in range(N + 1-len(data)):\n",
    "                feat.append(1)\n",
    "                feat.append(0)\n",
    "    else:\n",
    "        for i in range(N):\n",
    "            feat.append(0)\n",
    "            feat.append(data[-i-2]['rating'])  \n",
    "    return feat\n",
    "\n",
    "answers['Q4a'] = [featureMeanValue(10, dataset[0]['user_id']), featureMissingValue(10, dataset[0]['user_id'])]\n",
    "\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f9033ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4b'] = []\n",
    "\n",
    "for featFunc in [featureMeanValue, featureMissingValue]:\n",
    "    X = []\n",
    "    y = []\n",
    "    for user,rating in reviewsPerUser.items():\n",
    "        if len(rating) < 1:\n",
    "            continue\n",
    "        else:\n",
    "            X.append(featFunc(10,user))\n",
    "            y.append(rating[-1]['rating'])\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X)\n",
    "    mse = MSE(y, y_pred) \n",
    "    answers['Q4b'].append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4db5b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.54801312971192, 1.5354064599216142]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q4b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5356cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5\n",
    "#(a)\n",
    "def feature5(sentence):\n",
    "    feat = [1]\n",
    "    feat.append(len(sentence))\n",
    "    feat.append(sentence.count('!')) # Quadratic term\n",
    "    feat.append(sum(i.isupper() for i in sentence))\n",
    "    return feat\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for d in dataset:\n",
    "    for spoiler,sentence in d['review_sentences']:\n",
    "        X.append(feature5(sentence))\n",
    "        y.append(spoiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b760b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5a'] = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aa64e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "###5(b)\n",
    "mod = sklearn.linear_model.LogisticRegression( class_weight='balanced', C=1)\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)\n",
    "\n",
    "TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "FP = sum([(p and not l) for (p,l) in zip(predictions, y)])\n",
    "TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "FN = sum([(not p and l) for (p,l) in zip(predictions, y)])\n",
    "TPR = TP / (TP + FN)\n",
    "TNR = TN / (TN + FP)\n",
    "BER = 1 - 1/2 * (TPR + TNR)\n",
    "answers['Q5b'] = [TP, TN, FP, FN, BER]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "406d8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q5a']) == 4\n",
    "assertFloatList(answers['Q5b'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13158d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6\n",
    "def feature6(review):\n",
    "    review = review['review_sentences']\n",
    "    feat = [1]\n",
    "    for i in range(0, 5):\n",
    "        feat.append(review[i][0])\n",
    "    feat.append(len(review[5][1]))\n",
    "    feat.append(review[5].count('!')) # Quadratic term\n",
    "    feat.append(sum(i.isupper() for i in review[5][1]))\n",
    "    \n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "837c8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    sentences = d['review_sentences']\n",
    "    if len(sentences) < 6: continue\n",
    "    X.append(feature6(d))\n",
    "    y.append(sentences[5][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0f1d45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237],\n",
       " 'Q3a': [[1, 4, 4], [1, 4, 4, 4]],\n",
       " 'Q3b': [1.5608319121482275, 1.5409512373315701, 1.5396484853948436],\n",
       " 'Q4a': [[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       "  [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       " 'Q4b': [1.54801312971192, 1.5354064599216142],\n",
       " 'Q5a': [1, 121, 0, 4],\n",
       " 'Q5b': [2384, 168945, 86232, 3615, 0.4702652880062319],\n",
       " 'Q6a': [1, 0, 0, 0, 0, 0, 75, 0, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6a'] = feature6(dataset[0])\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4f8296b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237],\n",
       " 'Q3a': [[1, 4, 4], [1, 4, 4, 4]],\n",
       " 'Q3b': [1.5608319121482275, 1.5409512373315701, 1.5396484853948436],\n",
       " 'Q4a': [[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       "  [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       " 'Q4b': [1.54801312971192, 1.5354064599216142],\n",
       " 'Q5a': [1, 121, 0, 4],\n",
       " 'Q5b': [2384, 168945, 86232, 3615, 0.4702652880062319],\n",
       " 'Q6a': [1, 0, 0, 0, 0, 0, 75, 0, 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6a'] = X[0]\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cf2e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sklearn.linear_model.LogisticRegression(class_weight='balanced', C = 1)\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)\n",
    "\n",
    "TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "FP = sum([(p and not l) for (p,l) in zip(predictions, y)])\n",
    "TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "FN = sum([(not p and l) for (p,l) in zip(predictions, y)])\n",
    "TPR = TP / (TP + FN)\n",
    "TNR = TN / (TN + FP)\n",
    "BER = 1 - 1/2 * (TPR + TNR)\n",
    "\n",
    "answers['Q6b'] = BER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdcd7434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237],\n",
       " 'Q3a': [[1, 4, 4], [1, 4, 4, 4]],\n",
       " 'Q3b': [1.5608319121482275, 1.5409512373315701, 1.5396484853948436],\n",
       " 'Q4a': [[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       "  [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       " 'Q4b': [1.54801312971192, 1.5354064599216142],\n",
       " 'Q5a': [1, 121, 0, 4],\n",
       " 'Q5b': [2384, 168945, 86232, 3615, 0.4702652880062319],\n",
       " 'Q6a': [1, 0, 0, 0, 0, 0, 75, 0, 1],\n",
       " 'Q6b': 0.1759160163507989}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(answers['Q6a']) == 9\n",
    "assertFloat(answers['Q6b'])\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4446e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "760f8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50/25/25% train/valid/test split\n",
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5767cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(reg, bers, BER_test):\n",
    "    mod = linear_model.LogisticRegression(class_weight='balanced', C=reg)\n",
    "    \n",
    "    # 50/25/25% train/valid/test split\n",
    "    Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "    ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]\n",
    "    \n",
    "    mod.fit(Xtrain,ytrain)\n",
    "    ypredValid = mod.predict(Xvalid)\n",
    "    ypredTest = mod.predict(Xtest)\n",
    "    \n",
    "    # validation\n",
    "    \n",
    "    TP = sum([(a and b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    TN = sum([(not a and not b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    FP = sum([(not a and b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    FN = sum([(a and not b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    \n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    \n",
    "    BER = 1 - 0.5*(TPR + TNR)\n",
    "    \n",
    "    print(\"C = \" + str(reg) + \"; validation BER = \" + str(BER))\n",
    "    bers = bers.append(BER)\n",
    "    \n",
    "     # test\n",
    "\n",
    "    TP = sum([(a and b) for (a,b) in zip(ytest, ypredTest)])\n",
    "    TN = sum([(not a and not b) for (a,b) in zip(ytest, ypredTest)])\n",
    "    FP = sum([(not a and b) for (a,b) in zip(ytest, ypredTest)])\n",
    "    FN = sum([(a and not b) for (a,b) in zip(ytest, ypredTest)])\n",
    "    \n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    \n",
    "    BER = 1 - 0.5*(TPR + TNR)\n",
    "    \n",
    "    BER_test = BER_test.append(BER)\n",
    "\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "862df9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01; validation BER = 0.13379187509474\n",
      "C = 0.1; validation BER = 0.13310974685463095\n",
      "C = 1; validation BER = 0.1433681976656056\n",
      "C = 10; validation BER = 0.1423450053054418\n",
      "C = 100; validation BER = 0.1423450053054418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21350836985511912,\n",
       " 0.21299572460563176,\n",
       " 0.21316660635546092,\n",
       " 0.22262876442443003,\n",
       " 0.22245788267460087]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bers = []\n",
    "BER_test = []\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    pipeline(c, bers, BER_test)\n",
    "bers\n",
    "BER_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "256ccdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237],\n",
       " 'Q3a': [[1, 4, 4], [1, 4, 4, 4]],\n",
       " 'Q3b': [1.5608319121482275, 1.5409512373315701, 1.5396484853948436],\n",
       " 'Q4a': [[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       "  [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       " 'Q4b': [1.54801312971192, 1.5354064599216142],\n",
       " 'Q5a': [1, 121, 0, 4],\n",
       " 'Q5b': [2384, 168945, 86232, 3615, 0.4702652880062319],\n",
       " 'Q6a': [1, 0, 0, 0, 0, 0, 75, 0, 1],\n",
       " 'Q6b': 0.1759160163507989,\n",
       " 'Q7': [0.13379187509474,\n",
       "  0.13310974685463095,\n",
       "  0.1433681976656056,\n",
       "  0.1423450053054418,\n",
       "  0.1423450053054418,\n",
       "  0.1,\n",
       "  0.21299572460563176]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestC = 0.1\n",
    "ber = 0.21299572460563176\n",
    "answers['Q7'] = bers + [bestC] + [ber]\n",
    "assertFloatList(answers['Q7'], 7)\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bff80515",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a94acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75/25% train/test split\n",
    "dataTrain = dataset[:15000]\n",
    "dataTest = dataset[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f97ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few utilities\n",
    "\n",
    "itemAverages = defaultdict(list)\n",
    "ratingMean = []\n",
    "\n",
    "for d in dataTrain:\n",
    "    itemAverages[d['book_id']].append(d['rating'])\n",
    "    ratingMean.append(d['rating'])\n",
    "\n",
    "for i in itemAverages:\n",
    "    itemAverages[i] = sum(itemAverages[i]) / len(itemAverages[i])\n",
    "\n",
    "ratingMean = sum(ratingMean) / len(ratingMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5165609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "\n",
    "for d in dataTrain:\n",
    "    u,i = d['user_id'], d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    usersPerItem[i].add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e855b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From my HW2 solution, welcome to reuse\n",
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4c0989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [predictRating(d['user_id'], d['book_id']) for d in dataTest]\n",
    "labels = [d['rating'] for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6970f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q8\"] = MSE(predictions, labels)\n",
    "assertFloat(answers[\"Q8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e0ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f92ff3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6696633366192306"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 9\n",
    "item = [d['book_id'] for d in dataTrain]\n",
    "data0, rating0 =  [], []\n",
    "\n",
    "for d in dataTest:\n",
    "    num = item.count(d['book_id'])\n",
    "    if num == 0:\n",
    "        data0.append([d['user_id'], d['book_id']])\n",
    "        rating0.append(d['rating'])\n",
    "        \n",
    "pred0 = [predictRating(u, i) for u, i in data0]\n",
    "\n",
    "mse0 = MSE(pred0, rating0)\n",
    "mse0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9099b38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.052681872005889"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1, rating1 = [],[]\n",
    "\n",
    "for d in dataTest:\n",
    "    num = item.count(d['book_id'])\n",
    "    \n",
    "    if 1 <= num <= 5:\n",
    "        data1.append([d['user_id'], d['book_id']])\n",
    "        rating1.append(d['rating'])\n",
    "        \n",
    "\n",
    "pred1 = [predictRating(u, i) for u, i in data1]\n",
    "\n",
    "mse1to5= MSE(pred1, rating1)\n",
    "mse1to5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "089118c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.452063234864505"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5, rating5 = [], []\n",
    "\n",
    "for d in dataTest:\n",
    "    num = item.count(d['book_id'])\n",
    "        \n",
    "    if num > 5:\n",
    "        data5.append([d['user_id'], d['book_id']])\n",
    "        rating5.append(d['rating'])\n",
    "\n",
    "pred5 = [predictRating(u, i) for u, i in data5]\n",
    "\n",
    "mse5 = MSE(pred5, rating5)\n",
    "mse5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2328197a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ea8d7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237],\n",
       " 'Q3a': [[1, 4, 4], [1, 4, 4, 4]],\n",
       " 'Q3b': [1.5608319121482275, 1.5409512373315701, 1.5396484853948436],\n",
       " 'Q4a': [[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       "  [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       " 'Q4b': [1.54801312971192, 1.5354064599216142],\n",
       " 'Q5a': [1, 121, 0, 4],\n",
       " 'Q5b': [2384, 168945, 86232, 3615, 0.4702652880062319],\n",
       " 'Q6a': [1, 0, 0, 0, 0, 0, 75, 0, 1],\n",
       " 'Q6b': 0.1759160163507989,\n",
       " 'Q7': [0.13379187509474,\n",
       "  0.13310974685463095,\n",
       "  0.1433681976656056,\n",
       "  0.1423450053054418,\n",
       "  0.1423450053054418,\n",
       "  0.1,\n",
       "  0.21299572460563176],\n",
       " 'Q8': 1.8164934412791371,\n",
       " 'Q9': [1.742012484444442, 2.052681872005889, 1.452063234864505]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[\"Q9\"] = [mse0, mse1to5, mse5]\n",
    "assertFloatList(answers[\"Q9\"], 3)\n",
    "\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fba7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa0376b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6696633366192306"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userAverages = defaultdict(list)\n",
    "\n",
    "for d in dataTrain:\n",
    "    userAverages[d['user_id']].append(d['rating'])\n",
    "\n",
    "for i in userAverages:\n",
    "    userAverages[i] = sum(userAverages[i]) / len(userAverages[i])\n",
    "\n",
    "\n",
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            # return RatingMean\n",
    "            if user in userAverages:\n",
    "                return userAverages[user]\n",
    "            else:\n",
    "                return ratingMean\n",
    "            \n",
    "            \n",
    "item = [d['book_id'] for d in dataTrain]\n",
    "data10, rating10 = [], []\n",
    "\n",
    "for d in dataTest:\n",
    "    num = item.count(d['book_id'])\n",
    "    if num == 0:\n",
    "        data10.append([d['user_id'], d['book_id']])\n",
    "        rating10.append(d['rating'])\n",
    "        \n",
    "pred10 = [predictRating(u, i) for u, i in data10]\n",
    "\n",
    "mse10 = MSE(pred10, rating10)\n",
    "mse10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5233533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q10\"] = (\"To improve the prediction function for unseen items, we can modify the predictRating function. Since previously the predictRating only use itemAverages for prediction function, we can add the userAverage to specify the condition and make mse smaller, inside of just categorize data into ratingMean. We can see that the mse become smaller for unseen data.\", mse10)\n",
    "assert type(answers[\"Q10\"][0]) == str\n",
    "assertFloat(answers[\"Q10\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ce69a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1a': 1.970416294395752,\n",
       " 'Q1b': 2.051966103395068,\n",
       " 'Q2': [2.666035950804163, 2.1542691579943236, 2.0280931357090237],\n",
       " 'Q3a': [[1, 4, 4], [1, 4, 4, 4]],\n",
       " 'Q3b': [1.5608319121482275, 1.5409512373315701, 1.5396484853948436],\n",
       " 'Q4a': [[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       "  [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]],\n",
       " 'Q4b': [1.54801312971192, 1.5354064599216142],\n",
       " 'Q5a': [1, 121, 0, 4],\n",
       " 'Q5b': [2384, 168945, 86232, 3615, 0.4702652880062319],\n",
       " 'Q6a': [1, 0, 0, 0, 0, 0, 75, 0, 1],\n",
       " 'Q6b': 0.1759160163507989,\n",
       " 'Q7': [0.13379187509474,\n",
       "  0.13310974685463095,\n",
       "  0.1433681976656056,\n",
       "  0.1423450053054418,\n",
       "  0.1423450053054418,\n",
       "  0.1,\n",
       "  0.21299572460563176],\n",
       " 'Q8': 1.8164934412791371,\n",
       " 'Q9': [1.742012484444442, 2.052681872005889, 1.452063234864505],\n",
       " 'Q10': ('To improve the prediction function for unseen items, we can modify the predictRating function. Since previously the predictRating only use itemAverages for prediction function, we can add the userAverage to specify the condition and make mse smaller, inside of just categorize data into ratingMean. We can see that the mse become smaller for unseen data.',\n",
       "  1.6696633366192306)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "928ccf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
